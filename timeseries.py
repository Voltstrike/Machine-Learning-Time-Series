# -*- coding: utf-8 -*-
"""TimeSeries

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IXYuU_v2VdMYZxR0WbxTMJrLK-0gUGqC

Mikail Crito Husada
"""

import pandas as pd
import tensorflow as tf
import numpy as np

def dataset(dataset, time_step=1):
  X = []
  Y = []
  for i in range(len(dataset)-time_step-1):
    a = dataset[i:(i+time_step), 0]
    X.append(a)
    Y.append(dataset[i+time_step, 0])
  return np.array(X), np.array(Y)

"""read Dataset"""

df = pd.read_csv('Delhi_Weather.csv')
df.head()

df

"""Pengecekan data yang null"""

df.isnull().sum()

df1 = df[["datetime_utc"," _tempm"]]

df1.columns = ["date", "temp"]

df1.isnull().sum()

df1.dropna(inplace = True)

df1["date"] = pd.to_datetime(df1["date"])
df1.info()

df1=df1.set_index('date')

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range = (0, 1))
data1 = scaler.fit_transform(df1)

import matplotlib.pyplot as plt
plt.plot(data1)

train_size = int(len(data1)*0.8)
test_size = len(data1) - train_size
xdata, ydata = data1[0: train_size, :], data1[train_size: len(data1), :1]
train_size, test_size

x_train, y_train = dataset(xdata, 100)
x_test, y_test = dataset(ydata, 100)

x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)
x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout

model = Sequential([
    LSTM(64, return_sequences = True, input_shape=(100,1)),
    Dropout(0.1),
    LSTM(64, return_sequences = True),
    Dropout(0.1),
    Bidirectional(LSTM(64)),
    Dropout(0.1),
    Dense(8, activation='relu'),
    Dense(1)
])

from tensorflow.keras.callbacks import EarlyStopping
autostop_learn = EarlyStopping(
    monitor = 'loss',
    min_delta = 0,
    patience = 2,
    verbose = 1,
    mode = 'auto'
)

"""Train Model"""

optimizer = tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])

history = model.fit(
    x_train, y_train,
    validation_data = (x_test, y_test),
    epochs=30,
    batch_size = 130,
    callbacks = autostop_learn,
    verbose = 2
)

"""Grafik"""

#loss model
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss Model')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'test'], loc = 'lower left')
plt.show()

#Mae Model
plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('Mae Model')
plt.ylabel('Mae')
plt.xlabel('Epochs')
plt.legend(['train', 'test'], loc = 'lower left')
plt.show()